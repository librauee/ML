# 笔记摘要

## 应用案例
* 主要通过一个预测宝可梦进化后的CP(Combat Power)值的例子来介绍Regression。
* 因为输入的是带标签的数据，所以采用监督学习。
* 根据函数的输出类型宝可梦的CP值是一个连续型的数值，因而这里采用Regression是合适的。

![](https://github.com/librauee/ML/raw/master/picture/2-1.png)

## Regression过程

Machine Learning 的三个步骤：
1. 定义一个Model即function set；
2. 定义一个goodness of function损失函数去评估该function的好坏；
3. 找一个最好的function。

### Step 1:Model

* 这里使用Linear Model，即线性模型

$y=b+w \cdot X_{c p}$

$y$表示进化后的CP值，$X_{c p}$表示进化前的CP值，根据不同的w和b，可以确定无数的function，而这些funtion的集合便是function set。

![](https://github.com/librauee/ML/raw/master/picture/2-2.png)

### Step2：Goodness of Function

![](https://github.com/librauee/ML/raw/master/picture/2-3.png)

* $x^i$表示第$i$个宝可梦，$\hat{y}^{i} $表示第$i$个输出。
* 为了衡量function的好坏，我们使用Loss function，实际上是在衡量$w$和$b$参数的好坏。

$L(f)=L(w, b)$

* Loss function比较常用的方法有0-1损失、绝对损失和对数损失等。这里用到平方损失，一共有10只宝可梦的数据。

$L(f)=L(w, b)=\sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}$

![](https://github.com/librauee/ML/raw/master/picture/2-4.png)

### Step 3: Best Function

* 通过Loss function衡量model中每一个function 的好坏，并挑选一个最好的function,这个function便是loss最小的那个。

$w^{*}, b^{*}=\arg \min _{w, b} L(w, b)=\arg \min _{w, b} \sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}$


## 梯度下降(Gradient Descent)

* 只要$L(f)$是可微分的，那么梯度下降都可以找到表现好的参数，这里先考虑只有一个参数$w$的情况。
1. 首先随机选取一个初始值$w^0$ ;
2. 计算$L$在$w=w^0$
位置时的微分，即$\left.\frac{d L}{d w}\right|_{w=w^{0}}$，其几何意义是切线的斜率；
3. 如果切线斜率为负，那么应该使$w$增大，即往右踏一步；反之往左踏一步，每一步的步长就是$w$的变化量。

![](https://github.com/librauee/ML/raw/master/picture/2-5.png)

* 每次参数更新的大小是$\eta \frac{d L}{d w}$，满足斜率为负时$w$增大，反之减小，应当使原$L(f)$减去更新的数值，即

$$w^{1}=w^{0}-\left.\eta \frac{d L}{d w}\right|_{w=w^{0}}$$

* 当$w^{1}=0$时，参数就卡在这个点上无法更新，因此通过梯度下降更新得到的参数其实不一定是全局最优的。

![](https://github.com/librauee/ML/raw/master/picture/2-7.png)

* 但在线性回归上，损失函数为凸函数，局部最小便是全局最小。

![](https://github.com/librauee/ML/raw/master/picture/2-6.png)

其实同时考虑$w$和$b$，也是一回事。

$$\left(w^{*}, b^{*}\right)=\arg \min _{w, b} L(w, b)$$

* 首先随机选取两个初始值$w^0$和$b^0$;
* 接着分别计算在$(w^0,b^0)$点上$L$对$w$和$b$的偏微分，即$\left.\frac{\partial L}{\partial w}\right|_{w=w^{0}, b=b^{0}}$ 和 $\left.\frac{\partial L}{\partial b}\right|_{w=w^{0}, b=b^{0}}$
* 然后进行参数的更新，$w^{1} \leftarrow w^{0}-\left.\eta \frac{\partial L}{\partial w}\right|_{w=w^{0}, b=b^{0}}$，$b^{1} \leftarrow b^{0}-\left.\eta \frac{\partial L}{\partial b}\right|_{w=w^{0}, b=b^{0}}$，直至遇到两个偏导数均为0的情况。

实际上，L 的gradient就是微积分中的那个梯度的概念，即

$$\nabla L=\left[\begin{array}{l}\frac{\partial L}{\partial w} \\ \frac{\partial L}{\partial b}\end{array}\right]_{\text {gradient}}$$

## Pokemon

现在回到pokemon的问题上来，求具体的损失函数对$w$和$b$的偏微分。

$$\begin{array}{l}
L(w, b)=\sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2} \\
\frac{\partial L}{\partial w}=\sum_{n=1}^{10} 2\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)\left(-x_{c p}^{n}\right) \\
\frac{\partial L}{\partial b}=\sum_{n=1}^{10} 2\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)(-1)
\end{array}$$

* 定义宝可梦的实际CP值与预测值之差的绝对值为$e^i$,因此这个训练集的误差和为$\sum_{i=1}^{10} e^{i}=31.9$，但我们真正关心的是这个模型在测试集上的误差，因此我们将另外10只新的宝可梦当作测试集，算出误差和为$\sum_{i=1}^{10} e^{i}=35.0$，比测试集略高。

* 为了得到更好的结果，我们需要重新设计model，考虑更复杂的function，比如增加二次项、三次项甚至五次。

![](https://github.com/librauee/ML/raw/master/picture/2-8.png)

![](https://github.com/librauee/ML/raw/master/picture/2-9.png)

### 模型对比

* 这些不同模型在训练集随着$\left(x_{c p}\right)^{i}$高次项的增加，对应的平均误差越来越小，拟合得越来越好，但与此同时，模型在测试集得表现却越来越差。

![](https://github.com/librauee/ML/raw/master/picture/2-10.png)

* 在这个例子中，从含有$\left(x_{c p}\right)^{4}$项得模型开始，测试集上得误差出现了大幅增长，这就是过拟合(overfitting)。

![](https://github.com/librauee/ML/raw/master/picture/2-11.png)

* 因此模型不是越复杂越好，而是选择一个最适合的模型。

## 讨论其他参数的影响

### 考虑pokemon的种类

* 之前我们只考虑了宝可梦进化之前的CP值，我们显然还需要考虑更多的因素，比如宝可梦的种类。

![](https://github.com/librauee/ML/raw/master/picture/2-12.png)

* 回到step1,根据宝可梦不同的种类，设计不同的线性模型。

![](https://github.com/librauee/ML/raw/master/picture/2-13.png)

* 接着我们通过$\delta$条件表达式来合并线性模型，当条件表达式为真时，$\delta$得1，反之得0。

![](https://github.com/librauee/ML/raw/master/picture/2-14.png)

### 考虑Weight,Height,HP值

* 将这些都考虑在内，得到更加复杂的function，得到了不好的结果。

![](https://github.com/librauee/ML/raw/master/picture/2-15.png)


## Regularization

* 接着回到step2，重新衡量function的好坏，即加入正则化，来解决这个过拟合的问题。原先的loss function只考虑了预测的误差，而regularization则是在原来的基础上加上了$\lambda \sum\left(w_{i}\right)^{2}$，就是把这个模型中所有的权值的平方和用$\lambda$加权。

![](https://github.com/librauee/ML/raw/master/picture/2-16.png)

* 因为参数值接近0的function是比较平滑的，即在输入发生变化的时候，输出对输入的变化不太敏感。如果我们有一个相对平滑的function,因为输出对输入不敏感的原因，一些noise对function的影响就比较小。

### $\lambda$值的设置

* $\lambda$值越大代表正则项的影响力越大，得出的function就会更加平滑。

* 我们喜欢比较平滑的function,因为它对noise不那么敏感；但同时我们又不喜欢过于平滑的function，因为它对数据的拟合能力也大大下降了；而function的平滑程度，需要通过调整$\lambda$来决定。

![](https://github.com/librauee/ML/raw/master/picture/2-17.png)





